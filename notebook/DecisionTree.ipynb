{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_clean_data():\n",
    "    data = sio.loadmat('cleandata_students.mat')\n",
    "    return data['x'], data['y']\n",
    "\n",
    "def load_noisy_data():\n",
    "    data = sio.loadmat('noisydata_students.mat')\n",
    "    return data['x'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tree:\n",
    "    def __init__(self, op=None, kids=[], classification=None, pos=None, neg=None):\n",
    "        self.op = op\n",
    "        self.kids = kids\n",
    "        self.classification = classification\n",
    "        self.pos = pos\n",
    "        self.neg = neg\n",
    "    def pruneTree(self, validation_x, binary_classifier):\n",
    "        L = findAllParents(self)\n",
    "        non_changed = 0\n",
    "        for node in L:\n",
    "            initial_recall = calculateRecall(self, validation_x, binary_classifier)\n",
    "            \n",
    "            temp = node.kids\n",
    "            tempop = node.op\n",
    "            node.op = None\n",
    "            node.kids = []\n",
    "\n",
    "            if node.pos > node.neg:\n",
    "                node.classification = 1\n",
    "            else:\n",
    "                node.classification = 0\n",
    "            end_recall = calculateRecall(self, validation_x, binary_classifier)\n",
    "\n",
    "            if end_recall < initial_recall:\n",
    "                node.classification = None\n",
    "                node.kids = temp\n",
    "                node.op = tempop\n",
    "                non_changed += 1\n",
    "\n",
    "        if non_changed == len(L):\n",
    "            return False\n",
    "        return self.pruneTree(validation_x, binary_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transformation of classifier to binary classifier for given emotion number\n",
    "def to_binary_classifier(classifier, number):\n",
    "    bc=np.array([])\n",
    "    for x in range(0,classifier.size):\n",
    "        if classifier[x] == number:\n",
    "            bc=np.append(bc,1)\n",
    "        else:\n",
    "            bc = np.append(bc, 0)\n",
    "    return bc.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking if binary targets contain of one value (point uniquely to answer)\n",
    "def is_unique(bin_targets):\n",
    "    if bin_targets.size==np.sum(bin_targets) or np.sum(bin_targets)==0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "#Returning majority value of binary targets\n",
    "def majority_value(bin_targets):\n",
    "    if np.sum(bin_targets)>(bin_targets.size/2):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating entropy\n",
    "def entropy(p,n):\n",
    "    from math import log\n",
    "    if p+n==0: return 0\n",
    "    a=p/(p+n)\n",
    "    b=n/(p+n)\n",
    "    log2 = lambda x: log(x)/log(2)\n",
    "    if a==0 or b==0:\n",
    "        return 0\n",
    "    return (-a*log2(a)-b*log2(b))\n",
    "\n",
    "\n",
    "#Performing IG calculation for given attribute\n",
    "def attribute_calculation(examples,index,binary_targets):\n",
    "    p0, n0, p1, n1 = 0, 0, 0, 0\n",
    "    for x in range(0,binary_targets.size):\n",
    "        if binary_targets[x]==0:\n",
    "            if examples[x][index]==1:\n",
    "                n1 += 1\n",
    "            else:\n",
    "                n0 += 1\n",
    "        else:\n",
    "            if examples[x][index] == 1:\n",
    "                p1 += 1\n",
    "            else:\n",
    "                p0 += 1\n",
    "\n",
    "    p = np.sum(binary_targets)\n",
    "    n = binary_targets.size-p\n",
    "\n",
    "    e1 = entropy(p,n)\n",
    "    e2 = entropy(p0,n0)\n",
    "    e3 = entropy(p1,n1)\n",
    "\n",
    "    remainder = (p0+n0)*e2/(p+n)+(p1+n1)*e3/(p+n)\n",
    "    return e1 - remainder\n",
    "\n",
    "#Choosing maximum IG\n",
    "def choose_best_decision_attribute(examples,attributes,binary_targets,threshold):\n",
    "    index = 0\n",
    "    max = attribute_calculation(examples,index,binary_targets)\n",
    "    for x in range (0,attributes.size):\n",
    "        value = attribute_calculation(examples,x,binary_targets)\n",
    "        if max < value:\n",
    "            max = value\n",
    "            index = x\n",
    "    if max < threshold:\n",
    "        return 0\n",
    "    return attributes[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Learning\n",
    "\n",
    "def decision_tree_learning(examples,attributes,bin_targets,threshold):\n",
    "    if examples.size==0 or attributes.size==0:\n",
    "        return tree(classification=majority_value(bin_targets),pos=np.sum(bin_targets),neg=bin_targets.size-np.sum(bin_targets))\n",
    "    elif is_unique(bin_targets):\n",
    "        return tree(classification=bin_targets[0],pos=np.sum(bin_targets),neg=bin_targets.size-np.sum(bin_targets))\n",
    "    else:\n",
    "        best_attribute=choose_best_decision_attribute(examples,attributes,bin_targets,threshold)\n",
    "        if best_attribute==0:\n",
    "            return tree(classification=majority_value(bin_targets),pos=np.sum(bin_targets),neg=bin_targets.size-np.sum(bin_targets))\n",
    "        index=np.where(attributes==best_attribute)\n",
    "        index=index[0][0]\n",
    "        attributes=np.delete(attributes,index)\n",
    "\n",
    "        ex1=examples[examples[:,index]==1]\n",
    "        ex0=examples[examples[:,index]==0]\n",
    "\n",
    "        bt1=bin_targets[examples[:,index]==1]\n",
    "        bt0=bin_targets[examples[:,index]==0]\n",
    "\n",
    "        ex1=np.delete(ex1,index,axis=1)\n",
    "        ex0=np.delete(ex0,index,axis=1)\n",
    "\n",
    "        t1=decision_tree_learning(ex1, attributes, bt1, threshold)\n",
    "\n",
    "        t0=decision_tree_learning(ex0, attributes, bt0, threshold)\n",
    "\n",
    "        return tree(best_attribute,[t1,t0],pos=np.sum(bin_targets),neg=bin_targets.size-np.sum(bin_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Writing tree to newick format\n",
    "\n",
    "def to_newick(tree):\n",
    "    if tree.op==None:\n",
    "        if tree.classification==1:\n",
    "            return \"yes\"\n",
    "        else:\n",
    "            return \"no\"\n",
    "    else:\n",
    "        newick=\"AU\"+str(tree.op)\n",
    "        return \"(\"+to_newick(tree.kids[0])+\",\"+to_newick(tree.kids[1])+\")\"+newick\n",
    "\n",
    "\n",
    "#Counting leafs\n",
    "\n",
    "def isLeaf(tree):\n",
    "    if tree.classification!=None:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def countLeaves(tree):\n",
    "    if isLeaf(tree):\n",
    "        return 1\n",
    "    else:\n",
    "        return countLeaves(tree.kids[0])+countLeaves(tree.kids[1])\n",
    "\n",
    "'''\n",
    "attributes=np.arange(1,46)\n",
    "examples=data1\n",
    "bin_targets=to_binary_classifier(classification1,5)\n",
    "trained = decision_tree_learning(examples,attributes,bin_targets,0)\n",
    "\n",
    "new=to_newick(trained)+\";\"\n",
    "\n",
    "from ete3 import Tree as Tr\n",
    "from ete3 import TreeStyle, Tree, TextFace, add_face_to_node\n",
    "t = Tr(new,format=8)\n",
    "\n",
    "ts = TreeStyle()\n",
    "ts.rotation = 90\n",
    "ts.show_leaf_name = False\n",
    "def my_layout(node):\n",
    "        F = TextFace(node.name, tight_text=True)\n",
    "        add_face_to_node(F, node, column=0, position=\"branch-right\")\n",
    "ts.layout_fn = my_layout\n",
    "t.show(tree_style=ts)\n",
    "'''\n",
    "\n",
    "#Tests one tree, returns depth of classification and classification\n",
    "def test_one_tree(tree,features,depth):\n",
    "    if tree.classification!=None:\n",
    "        return [tree.classification,depth+1]\n",
    "    if features[tree.op-1]==1:\n",
    "        return test_one_tree(tree.kids[0],features,depth+1)\n",
    "    else:\n",
    "        return test_one_tree(tree.kids[1],features,depth+1)\n",
    "\n",
    "#Tests set of trained trees T on x2\n",
    "def testTrees(T,x2):\n",
    "    L=[]\n",
    "    for index in range(0,x2.shape[0]):\n",
    "        output = 7\n",
    "        depth = 100\n",
    "        depths=[]\n",
    "        for t_num in range(0,T.size):\n",
    "            test=test_one_tree(T[t_num],x2[index],0)\n",
    "            if test[0]==1 and test[1]<depth:\n",
    "                output = t_num+1\n",
    "            depths.append(test[1])\n",
    "        #in case none of the trees predict the thing - randomize\n",
    "        #import random\n",
    "        if output==7:\n",
    "            output=depths.index(max(depths))+1\n",
    "            #output=random.randint(1, 6)\n",
    "\n",
    "        L.append(output)\n",
    "    return L\n",
    "\n",
    "#Creating confusion matrix\n",
    "\n",
    "def confusion_matrix_10_cross(data,classification,threshold=0,prune=0):\n",
    "    ''' Creating slices '''\n",
    "    x_slices = np.vsplit(data[:900, :], 9)\n",
    "    x_l_slice = data[900:, :]\n",
    "    x_slices.append(x_l_slice)\n",
    "\n",
    "    y_slices = np.vsplit(classification[:900], 9)\n",
    "    y_l_slice = classification[900:]\n",
    "    y_slices.append(y_l_slice)\n",
    "\n",
    "    confusion_matrix = np.zeros((6,6), dtype=np.int)\n",
    "\n",
    "    ''' i = ith cross-validation run '''\n",
    "    for i in range(0,10):\n",
    "        train_x = np.empty((0, 45), int)\n",
    "        train_y = np.empty((0,1), int)\n",
    "\n",
    "        for j in range (0,10):\n",
    "            if j==i:\n",
    "                test_x = x_slices[j]\n",
    "                test_y = y_slices[j]\n",
    "            else:\n",
    "                train_x = np.concatenate((train_x, x_slices[j]), axis=0)\n",
    "                train_y = np.concatenate((train_y, y_slices[j]), axis=0)\n",
    "\n",
    "        attributes = np.arange(1, 46)\n",
    "\n",
    "        ''' Training on train data '''\n",
    "        L=[]\n",
    "\n",
    "        for i in range(1,7):\n",
    "            L.append(decision_tree_learning(train_x,attributes,to_binary_classifier(train_y,i),threshold))\n",
    "            if prune==1:\n",
    "                L[i-1].pruneTree(test_x,to_binary_classifier(test_y,i))\n",
    "        T = np.array(L)\n",
    "\n",
    "        results = testTrees(T,test_x)\n",
    "\n",
    "        for i in range(0, test_y.size):\n",
    "            confusion_matrix[test_y[i] - 1, results[i] - 1]+=1\n",
    "\n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(0,16):\n",
    "    print(i*0.005)\n",
    "    cm=confusion_matrix_10_cross(data1,classification1,i*0.01)\n",
    "    print((cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4]+cm[5,5])/np.sum(cm))\n",
    "'''\n",
    "\n",
    "#Finds all nodes that are parents to two leaves\n",
    "def findAllParents(tree):\n",
    "    L=[]\n",
    "    if isLeaf(tree):\n",
    "        return L\n",
    "    elif isLeavesParent(tree):\n",
    "        L.append(tree)\n",
    "        return L\n",
    "    else:\n",
    "        K=findAllParents(tree.kids[0])\n",
    "        M=findAllParents(tree.kids[1])\n",
    "        L.extend(K)\n",
    "        L.extend(M)\n",
    "        return L\n",
    "\n",
    "\n",
    "#Checks if a node is a parent to two leaves\n",
    "def isLeavesParent(tree):\n",
    "    if isLeaf(tree.kids[0]) and isLeaf(tree.kids[1]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "'''\n",
    "train_x = data1[:700,:]\n",
    "validation_x = data1[700:900,:]\n",
    "test_x = data1[900:,:]\n",
    "\n",
    "train_y = classification1[:700,:]\n",
    "validation_y = classification1[700:900,:]\n",
    "test_y = classification1[900:,:]\n",
    "\n",
    "\n",
    "L=[]\n",
    "for i in range(1,7):\n",
    "    L.append(decision_tree_learning(train_x,attributes,to_binary_classifier(train_y,i),0))\n",
    "\n",
    "L[i-1].pruneTree(validation_x,to_binary_classifier(train_y,i))\n",
    "'''\n",
    "#Calculates recall on single tree\n",
    "def calculateRecall(tree,data,labels):\n",
    "    counter=0\n",
    "    for index in range(0,data.shape[0]):\n",
    "        if test_one_tree(tree,data[index],0)[0]==labels[index]:\n",
    "            counter+=1\n",
    "    return counter/data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95  18   5   2   8   4]\n",
      " [  7 167   2   7  10   5]\n",
      " [  1   3  86   5   5  19]\n",
      " [  3   6   1 196   5   5]\n",
      " [ 14  20   1   3  86   8]\n",
      " [  0   4   9   2   4 188]]\n",
      "0.814741035857\n",
      "[[ 73  25   4   8  20   2]\n",
      " [  9 145   3  14  17  10]\n",
      " [  4   5  82   3   9  16]\n",
      " [  1   8   2 178  18   9]\n",
      " [ 13  15   4   7  84   9]\n",
      " [  3   5  11   3   6 179]]\n",
      "0.738047808765\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix_10_cross(data1,classification1,prune=1)\n",
    "print(cm)\n",
    "print((cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4]+cm[5,5])/np.sum(cm))\n",
    "\n",
    "cm=confusion_matrix_10_cross(data1,classification1,prune=0)\n",
    "print(cm)\n",
    "print((cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4]+cm[5,5])/np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
