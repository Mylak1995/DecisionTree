{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from math import log2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data and some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_clean_data():\n",
    "    data = sio.loadmat('cleandata_students.mat')\n",
    "    return data['x'], data['y']\n",
    "\n",
    "def load_noisy_data():\n",
    "    data = sio.loadmat('noisydata_students.mat')\n",
    "    return data['x'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMOTIONS = ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n",
    "\n",
    "def label_to_string(label):\n",
    "    if label == 1:\n",
    "        return 'anger'\n",
    "    elif label == 2:\n",
    "        return 'disgust'\n",
    "    elif label == 3:\n",
    "        return 'fear'\n",
    "    elif label == 4:\n",
    "        return 'happiness'\n",
    "    elif label == 5:\n",
    "        return 'sadness'\n",
    "    elif label == 6:\n",
    "        return 'surprise'\n",
    "    else:\n",
    "        return 'Unknown emotion label'\n",
    "\n",
    "def string_to_label(s):\n",
    "    if s == 'anger':\n",
    "        return 1\n",
    "    elif s == 'disgust':\n",
    "        return 2\n",
    "    elif s == 'fear':\n",
    "        return 3\n",
    "    elif s == 'happiness':\n",
    "        return 4\n",
    "    elif s == 'sadness':\n",
    "        return 5\n",
    "    elif s == 'surprise':\n",
    "        return 6\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turns targets into binary targets depending on the emotion\n",
    "# the values are of bool type, but it's ok because False == 0 and True ==0\n",
    "def to_binary_targets(targets, emotion):\n",
    "    if isinstance(emotion, str):\n",
    "        emotion = string_to_label(emotion)\n",
    "    return (targets == emotion).astype(int)\n",
    "\n",
    "#Checking if binary targets contain of one value (point uniquely to answer)\n",
    "def all_the_same(bin_targets):\n",
    "    return np.all(bin_targets == bin_targets[0])\n",
    "\n",
    "#Returning majority value of binary targets\n",
    "def majority_value(bin_targets):\n",
    "    if np.sum(bin_targets) > (bin_targets.size/2):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "#Calculates recall on single tree\n",
    "def calculate_recall(tree, examples, binary_targets):\n",
    "    counter=0\n",
    "    for index in range(0,examples.shape[0]):\n",
    "        if classify(tree,examples[index],0)[0]==binary_targets[index]:\n",
    "            counter+=1\n",
    "    return counter/examples.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, op=None, kids=[], classification=None, pos=None, neg=None):\n",
    "        self.op = op\n",
    "        self.kids = kids\n",
    "        self.classification = classification   # tree.class from the specs, but class is a keyword\n",
    "        self.pos = pos\n",
    "        self.neg = neg\n",
    "    def is_leaf(self):\n",
    "        return (self.classification != None)\n",
    "    def count_leaves(self):\n",
    "        if self.is_leaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return self.kids[0].count_leaves() + self.kids[1].count_leaves()\n",
    "\n",
    "def prune_tree(tree, validation_examples, binary_targets):\n",
    "    return prune_tree_aux(tree, tree, validation_examples, binary_targets)\n",
    "\n",
    "def prune_tree_aux(tree, node, validation_examples, binary_targets):\n",
    "    if not node.kids: # it's a leaf\n",
    "        return node\n",
    "    node.kids[0] = prune_tree_aux(tree, node.kids[0], validation_examples, binary_targets)\n",
    "    node.kids[1] = prune_tree_aux(tree, node.kids[1], validation_examples, binary_targets)\n",
    "    if node.kids[0].is_leaf() and node.kids[1].is_leaf():\n",
    "        initial_recall = calculate_recall(tree, validation_examples, binary_targets)\n",
    "        temp_kids = node.kids\n",
    "        temp_op = node.op\n",
    "        node.op = None\n",
    "        node.kids = []\n",
    "        \n",
    "        if node.pos > node.neg:\n",
    "            node.classification = 1\n",
    "        else:\n",
    "            node.classification = 0\n",
    "        end_recall = calculate_recall(tree, validation_examples, binary_targets)\n",
    "        \n",
    "        if end_recall < initial_recall:\n",
    "            node.classification = None\n",
    "            node.kids = temp_kids\n",
    "            node.op = temp_op\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating entropy\n",
    "def entropy(p, n):\n",
    "    from math import log\n",
    "    if p+n == 0: return 0\n",
    "    a = p/(p+n)\n",
    "    b = n/(p+n)\n",
    "    log2 = lambda x: log(x)/log(2)\n",
    "    if a == 0 or b == 0:\n",
    "        return 0\n",
    "    return (-a*log2(a)-b*log2(b))\n",
    "\n",
    "\n",
    "#Performing IG calculation for given attribute\n",
    "def attribute_calculation(examples, index, binary_targets):\n",
    "    p0, n0, p1, n1 = 0, 0, 0, 0\n",
    "    for x in range(0, binary_targets.size):\n",
    "        if binary_targets[x] == 0:\n",
    "            if examples[x][index] == 1:\n",
    "                n1 += 1\n",
    "            else:\n",
    "                n0 += 1\n",
    "        else:\n",
    "            if examples[x][index] == 1:\n",
    "                p1 += 1\n",
    "            else:\n",
    "                p0 += 1\n",
    "\n",
    "    p = np.sum(binary_targets)\n",
    "    n = binary_targets.size-p\n",
    "\n",
    "    e1 = entropy(p, n)\n",
    "    e2 = entropy(p0, n0)\n",
    "    e3 = entropy(p1, n1)\n",
    "\n",
    "    remainder = (p0+n0)*e2/(p+n)+(p1+n1)*e3/(p+n)\n",
    "    return e1 - remainder\n",
    "\n",
    "#Choosing maximum IG\n",
    "def choose_best_decision_attribute(examples, attributes, binary_targets, threshold=0):\n",
    "    index = 0\n",
    "    max_gain = attribute_calculation(examples, index, binary_targets)\n",
    "    for x in range (0, attributes.size):\n",
    "        value = attribute_calculation(examples, x, binary_targets)\n",
    "        if max_gain < value:\n",
    "            max_gain = value\n",
    "            index = x\n",
    "    if max_gain < threshold:\n",
    "        return 0\n",
    "    return attributes[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_tree_learning(examples, attributes, bin_targets, threshold=0):\n",
    "    if examples.size == 0 or attributes.size == 0:\n",
    "        return Tree(classification=int(majority_value(bin_targets)), pos=np.sum(bin_targets), neg=bin_targets.size-np.sum(bin_targets))\n",
    "    elif all_the_same(bin_targets):\n",
    "        return Tree(classification=int(bin_targets[0]), pos=np.sum(bin_targets), neg=bin_targets.size-np.sum(bin_targets))\n",
    "    else:\n",
    "        best_attribute = choose_best_decision_attribute(examples, attributes, bin_targets, threshold)\n",
    "        if best_attribute == 0:\n",
    "            return Tree(classification=int(majority_value(bin_targets)), pos=np.sum(bin_targets), neg=bin_targets.size-np.sum(bin_targets))\n",
    "        index = np.where(attributes==best_attribute)\n",
    "        index = index[0][0]\n",
    "        attributes = np.delete(attributes, index)\n",
    "\n",
    "        ex1 = examples[examples[:,index]==1]\n",
    "        ex0 = examples[examples[:,index]==0]\n",
    "\n",
    "        bt1 = bin_targets[examples[:,index]==1]\n",
    "        bt0 = bin_targets[examples[:,index]==0]\n",
    "\n",
    "        ex1 = np.delete(ex1,index,axis=1)\n",
    "        ex0 = np.delete(ex0,index,axis=1)\n",
    "\n",
    "        t1 = decision_tree_learning(ex1, attributes, bt1, threshold)\n",
    "\n",
    "        t0 = decision_tree_learning(ex0, attributes, bt0, threshold)\n",
    "\n",
    "        return Tree(best_attribute, [t1,t0], pos=np.sum(bin_targets), neg=bin_targets.size-np.sum(bin_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_width(node):\n",
    "    if node.is_leaf():\n",
    "        return 1\n",
    "    return tree_width(node.kids[0]) + tree_width(node.kids[1])\n",
    "\n",
    "def tree_height(node):\n",
    "    if not node:\n",
    "        return 0\n",
    "    if not node.kids:\n",
    "        return 1\n",
    "    return max(tree_height(node.kids[0]), tree_height(node.kids[1])) + 1\n",
    "\n",
    "def draw_tree(draw, node, x, y):\n",
    "    if node.is_leaf():\n",
    "        draw.text((x-2,y), str(node.classification), (0,0,0))\n",
    "    else:\n",
    "        # false is the left branch\n",
    "        wt = tree_width(node.kids[1]) * 20\n",
    "        wf = tree_width(node.kids[0]) * 20\n",
    "        left = x - (wt + wf)/2\n",
    "        right = x + (wt + wf)/2\n",
    "        draw.text((x-2,y-1), str(node.op), (0,0,0))\n",
    "        draw.line((x,y,left+wf/2,y+30), fill=(255,0,0))\n",
    "        draw.line((x,y,right-wt/2,y+30), fill=(255,0,0))\n",
    "        draw_tree(draw, node.kids[0], left+wf/2, y+30)\n",
    "        draw_tree(draw, node.kids[1], right-wt/2, y+30)\n",
    "\n",
    "def visualize_tree(tree):\n",
    "    w = tree_width(tree) * 20\n",
    "    h = tree_height(tree) * 30 + 10\n",
    "    img = Image.new('RGB', (w,h), (255,255,255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw_tree(draw, tree, w/2, 5)\n",
    "    img.save('tree.jpg','JPEG')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAACCCAYAAABGk796AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFU1JREFUeJztnX+sHcdVxz/fOj+api1JiDHGthSDLCIHif54MoEiFDWU\nmFDV+StyRcEVQf4nSClUQk4rgfpHpBRQQQgFZDUFA6WR1abEioraYCpVSDTJS2na2Gma16YhNk7s\nqiotIKVNOPxx59r7rnfv3b07uzuz73ykp7c7uzt75szMntnZM+fKzHAcx3Gc1wwtgOM4jpMGbhAc\nx3EcwA2C4ziOE3CD4DiO4wBuEBzHcZyAGwTHcRwH6NAgSNor6RlJa5IOdXUfx3EcJw7qYh2CpE3A\n14F3AKeAx4F3m9nJ6DdzHMdxotDVG8IeYM3MvmlmPwAeAPZ1dC/HcRwnApd0lO824IXC/ing54on\nSDoIHAS48sor33r99dd3JIrjOM44eeKJJ75tZptj5deVQViImR0GDgOsrKzY6urqUKI4zgWkC9vF\n6dRpekiThId9cYZG0vMx8+vKIJwGdhT2t4c0x+mH4oMd1j/c5zFzngr5LDQAM0bDcXKjq28IjwO7\nJO2UdBmwHzjW0b2csSNd+KuL2fq/JTGz838LjUOdezUth+P0SCdvCGb2iqTfAT4LbAI+ZmYnuriX\nkxlVUzLzSGTEHWWKqO5bRp1zHScynX1DMLPPAJ/pKn9nYJZ9cPlDbj519ONGw+mIwT4qOwOy7Px6\n22ucODTVvX/bcGriBiF3Mp6CcXrCp6mcmrhBSI2moznvwE5b6rYhydvbyPHgdkNS5m0y66niXilO\n31S1ueBppbJj3k5Hgb8h9MnsCKvOaKvsHB+pObEoa0tz2lalp5Wv0RgF/obQJTE+3pZRZSQcp4qq\n9tHXA3rRGg1vv0ngBiEWVdM/fVF1L+9oG4d5dZ36yLyuu623505xg7AsXY3+Y+NvE+Nj6NH+UNR5\ny/C23Qo3CHXJxQDUYVZ270hpMufjrlPCPIPhbbwW/lG5imU+AOeKf7gelqoPrq7/ePhH71r4G8KU\nOW8Ala52Y6bsLQI2nh46RhICNNlx/Q5F1dvFBquTjf2GUBwFF+LcT9nw8e7DwwrW60ISNkkcQqo8\nqXjjmm1j6/b8La13Lur/ZusHiyOvk41lEGpMA5UZgQ1rGMyYLflcXYy8s7QiVrwon9rolIX9f943\nihHUyfinjGLGadlAr45LUTHNtCHoq6xlUxsbSc+pMpI6GadB6CpY1whGAL0ykk5SSkpeZ2PWc1d0\nraNM3b0XGgRJH5N0VtJThbRrJD0i6dnw/+rCsbslrUl6RtItXQk+lz46ZwaVmxxlv1GcE7lEBXUD\nMZ+hpncyqJc6bwh/A+ydSTsEHDezXcDxsI+k3Ux+LvOGcM19kjZFk7bI0MpM+YGQAxl0jovItc5z\n1HWXpFKPCb5FLDQIZvYF4DszyfuAI2H7CHBbIf0BM3vZzJ4D1oA9kWSdkNhHNZUseMnaTS242RVd\nbWf3O6HEy2tIZsvbiw76InjOlNXzmJn21dlyJlXuQj8oq5uuZV32G8IWMzsTtl8EtoTtbcALhfNO\nhbSLkHRQ0qqk1XPnztW+cZm/9tAVqgRkWJqSufDiD8s7F8haJxXfPGbLNBqjV1KGqRtpDnU4VB9s\n/VHZJhI3ltrMDpvZipmtbN68ef7JJb7BRUUNWcEXVZyUfoNrOBfeZ+PsVXdzHnyz5U28RstZUM8X\nrYHIfSCw5Dee5MpbZczoXtZlDcJLkrYChP9nQ/ppYEfhvO0hrR2pVdg8UpU1lw+iXbOsHnLUWY4y\nNyVGu07tjWjAelvWIBwDDoTtA8BDhfT9ki6XtBPYBTzWTsQKUqvE1NkID4c6uB7yJ/bgxtvEeRau\nVJb0CeAm4FpJp4A/BO4Fjkq6A3geuB3AzE5IOgqcBF4B7jSzVzuRPJdKHMkKxizpWvdD1+3Q9x+K\nMdfpwCw0CGb27opDN1ecfw9wz9ISja1CprFQui7T2PQWg671MYS+S+JvOREZWqcD9+OkViqroTJi\numaVuRVG87gwK81/eo9lUcWrc2deIiWuip3erwklMvTpMdObm2qX7rlzXFH7rOMy99DevZ8Sccst\nu2eXciRlEJp+QS/zkujr3snk32cj7cnTYRmm7siD06Ex7jzfgodRX14tZRgwSE0u0MWF07qTbjbn\nvvWffbTTmNFJYxqYOvm3uscc99Yocle8rVmYAkvF7XeeDH3K1WnbKamLaPnX1FuvdWwNo+xGvO/F\nSRe38y4Hd3Xy7lIXSb0hOA0Ycn48AQOQxNtAX8TSd846iy17irpIoF+5QRgDbRt3ip1jEVWdJ8ey\n1KVt2RJ44CykqoyxZc9BFwPgBiE3yjpM28a9zPWpPnjH1tGX9blPtX4W0UX95aCLRGR0g5AbbTpM\nzEbX94M3kQ7TO8sagbb1k7q+F8mXmy4SeeMdrUGI6aZWO58Kl9Jl5Wh0XcW5Va6prenZHa7N6Lgr\nuVrl24WMMet3qDUW63bn9J9F8nWsiz7cYJu64ccgeYNQR+llDWfpIF0VFV2nASwb9bTK77qJu9v0\n3p37LU/zKqytSI15ulg+U52vpyjZzexb0Of6W9aryy7qYJD1B6yvt2X6b5+6iOXtU5b/tP/33ceS\ndztdqPTpg7OgwFrXVd9w4vImne+0dfOaDSNc103t/HmF65q6/i1779pMRyslbnitdR6ZKl20zPS8\nK2Tr8hbabLGN1XFd7cQltMqtNVafqnn/GG04R13M5l9sC74OoSlThcVWYIkv9FyKDanFQ2jZtxpC\no5rtWNGoaYySoUNdtM6z0GYH1VyJkV9HHw+l2Qdwl224jhxD6WIgAzBL8lNGvdLm1axYkX1X6oxR\nbE2C00Bz6cLzalH+dY6lSmHab3A5ZmUYyllhaF0kwrgMQhd+2jl2+Lbk1jlyWqQ3VHtK0X11qHaW\noi76yL8G4zIIPU+VLKSJa9xQpCDDWKijy9xGwLkNDuaRmi5m20sCuh6XQWhDFw/GNq5xfY1GYjTC\nMRuVJmWbfsdJiQQeMsmQmi5Sk4caBkHSDkmfl3RS0glJd4X0ayQ9IunZ8P/qwjV3S1qT9IykW2IK\nvNANq8R9s/i/kgoXr6XdSOtcP0fWZR8rteWN7KcdO7T3IpqsDWkVqruh69/cs2baYlfhnaPlNc2j\nRIfL3qPJNa3qrXBdTF3M5tcm775DW9ehzhvCK8D7zWw3cCNwp6TdwCHguJntAo6HfcKx/cANwF7g\nPkmbYgk8d31BiYdCE/etKte/po2qlqdAS1knWVwsV5NrY1LXbbJ3KnTcLItIXi8F98JZWWL+uH3r\nvGbfHkt0GFPeKmJE1I1ad9P8ZvIfEwsNgpmdMbMvhe3vA08D24B9wJFw2hHgtrC9D3jAzF42s+eA\nNWBPbMErhG13fcVDsk2jqrxuQX7LGrC6RG/IPY9seu2IMQcDKT9AevC4yeoBWlXvEQ13nbQ+afQN\nQdJ1wJuBR4EtZnYmHHoR2BK2twEvFC47FdJm8zooaVXS6rlz5xqK3RFtPEZSmzuOSYofSxcxK3OD\nKaaLSK1sXZFCOZetty5kSEEfPVPbIEh6PfAp4H1m9r3iMZuYtUbaM7PDZrZiZiubN29ucmmVgO3z\naMqQaw/6IOeOsYx/e5lffBekMnhIRY4iQ69LaHLPFPXXkloGQdKlTIzBx83swZD8kqSt4fhW4GxI\nPw3sKFy+PaR1S06LslJvSMsagtTLtYi+vL6GNrA5G/quWKZ+R6i/Ol5GAu4HnjazjxQOHQMOhO0D\nwEOF9P2SLpe0E9gFPBZP5I7pY3SQekNKxU97WbpYWZxK2drQ1hAMuTCrq3u7cVxHnVhGbwN+A/iq\npC+HtA8A9wJHJd0BPA/cDmBmJyQdBU4y8VC608xejS55garIoHU+0MyeVzd4lbh4jqzOPcvyjxaA\nrSVdyDFE2TS5MXCxnqHh3OaFiy96aCzbxppcG4sY95un1xhl6aTe6ty3rfwzbSO1YI9NWGgQzOxf\nqXavvrnimnuAe1rI1ZqcKiMnWechaRKxlWEN3ryH77JyCLCwPmQs9VWbEhfpSXJ81+Uu8y9j9g5N\n2+p5GRMZ1LUl/2intOugy/rOL+sylnKjaSvb+YduxDwbMx2tFUZtMUIJtylbCu6Fre43e22FgWjF\nnHrrkrZrZ1Ko25h46AqnOSl/PC4spnJaMK+Ou9DtkPWWcnvuGTcITnP8YTtu+nK/HZKiERh7WRvg\nBsGpRw6jqBQWNY2Bof3w+6g3NwKluEFw6pFDB4q5qMmNyWK6WvuT+7RRxm3HDYLTDTMRMWtHnU2E\neVLORvvMpUxVtIm6WaWLRlFNa5/ZHYui1DYNcBkzKmqfuEFwKmkTOnh6VV8RUGOGj15EmddSn/eP\njcH5h17jayt0kbOnzSxlrsbz6rvKNTmH9jEKt1OnG4Zw5411v87ymxO2PFtaugvHCC8+NPNkqApX\nvvD8mvmnhL8hOO2pGvlkMCJqzLRjj7Fsy+K6uEDm3ktuEJx2zHNRzLBD1GYsZYsRwn0suiijqU4y\n14UbBKcdmXeARoxxJFysv41Ul3WJoZOM2o0bBKdbMuoMCykL4eBMcF1Uk5GhdYPgNGLZH1Yfi4vm\nOjLq6GXUdTdt6oLa9LpUaaqLee7IuejCDYLTKbMueLl4W8ySs1tpH4wxCuyyge6aeiWlhLudOo1o\n20lyJXf5y6gbqbN2FN+Z9QcbRWdNjqdOnV9Me62kxyQ9KemEpA+F9GskPSLp2fD/6sI1d0tak/SM\npFu6LICTMD6i3lhk/jCMQuZtvs6U0cvA283sZ4E3AXsl3QgcAo6b2S7geNhH0m5gP3ADsBe4T9Km\nLoR3EscfEM5GI/M2v9Ag2IT/DruXhj8D9gFHQvoR4LawvQ94wMxeNrPngDVgT1SpHcdJk8xHyBud\nWh+VJW0Kv6d8FnjEzB4FtpjZmXDKi8CWsL0NeKFw+amQNpvnQUmrklbPnTu3dAGcRPEHw7ipqt/M\nR8hRyLjt1zIIZvaqmb0J2A7skfQzM8eNhr+BbWaHzWzFzFY2b97c5FInB/zBMG68fqvJWDeN3E7N\n7LvA55l8G3hJ0laA8P9sOO00sKNw2faQ5mwg3E1z41K2HmEjtYecy1nHy2izpKvC9hXAO4CvAceA\nA+G0A8BDYfsYsF/S5ZJ2AruAx2IL7qSNFSKC5txBnIYE11MzO28Epvu5u2TWJedy1lmHsBU4EjyF\nXgMcNbOHJf0bcFTSHcDzwO0AZnZC0lHgJPAKcKeZvdqN+E4O5NxBnIaMfB3C2FEKlbaysmKrq6tD\ni+E4jpMVkp4ws5VY+XnoCsdx4uBTg9njBsHpFn9IbBwSmG1w2uEGwWnPvIe+PyQ2Lj4YyA43CE5r\n5nb7MYa9durhg4HscIPgdEtJFExnfJStM/BBQH54+GunNQsf9m4MRs+yYbOdtPA3BMdxHAdwg+D0\nhU8fOE7yuEFw+sGnDxwnedwgOI7jOIAbBKcjyjxM3OvEcdLGDYLjOI4DuEFwOsLdEB0nP9wgOI7j\nOIAbBMdxHCdQ2yBI2iTp3yU9HPavkfSIpGfD/6sL594taU3SM5Ju6UJwx3EcJy5N3hDuAp4u7B8C\njpvZLuB42EfSbmA/cAOT316+L/zamuM4jpMwtQyCpO3ArwEfLSTvA46E7SPAbYX0B8zsZTN7DlgD\n9sQR13Ecx+mKusHt/gz4feANhbQtZnYmbL8IbAnb24AvFs47FdLWIekgcDDsvizpqbpCJ8i1wLeH\nFqIFLv+wuPzDkbPsAD8dM7OFBkHSO4GzZvaEpJvKzjEzk9TIp9DMDgOHwz1WY/4uaN+4/MPi8g9L\nzvLnLDtM5I+ZX503hLcB75J0K/Ba4I2S/h54SdJWMzsjaStwNpx/GthRuH57SHMcx3ESZuE3BDO7\n28y2m9l1TD4W/4uZvQc4BhwIpx0AHgrbx4D9ki6XtBPYBTwWXXLHcRwnKm1+IOde4KikO4DngdsB\nzOyEpKPASeAV4E4ze3VBXodbyJECLv+wuPzDkrP8OcsOkeWXhxNwHMdxwFcqO47jOAE3CI7jOA6Q\ngEGQtDeEuFiTdGhoeWaRtEPS5yWdlHRC0l0hPavQHTmHHpF0laRPSvqapKcl/Xxm8v9uaDtPSfqE\npNemLL+kj0k6W1wbtIy8kt4q6avh2J+rpx/EqJD/j0P7+YqkT0u6Kif5C8feL8kkXduJ/GY22B+w\nCfgG8JPAZcCTwO4hZSqRcSvwlrD9BuDrwG7gj4BDIf0Q8OGwvTuU43JgZyjfpgTK8XvAPwAPh/1s\n5GeyEv63w/ZlwFW5yM9kUeZzwBVh/yjw3pTlB34JeAvwVCGtsbxMvAtvBAT8E/CrA8r/K8AlYfvD\nuckf0ncAn2XixHNtF/IP/YawB1gzs2+a2Q+AB5iEvkgGMztjZl8K299nEs9pGxmF7lDGoUck/QiT\nDnI/gJn9wMy+SybyBy4BrpB0CfA64D9JWH4z+wLwnZnkRvKGtUlvNLMv2uTp9LeFazqlTH4z+5yZ\nvRJ2v8hkfVQ28gf+lEnEiKInUFT5hzYI24AXCvulYS5SQdJ1wJuBR5kfuiO1Mk1Dj/xfIS0X+XcC\n54C/DlNeH5V0JZnIb2angT8B/gM4A/yXmX2OTOQv0FTebWF7Nj0FfovJiBkykV/SPuC0mT05cyiq\n/EMbhGyQ9HrgU8D7zOx7xWPBAifpv6tC6JGqc1KWn8no+i3AX5rZm4H/IUTWnZKy/GGufR8Tw/YT\nwJWS3lM8J2X5y8hN3iKSPshkfdTHh5alLpJeB3wA+IOu7zW0QcgizIWkS5kYg4+b2YMh+aXwWobS\nDt0xDT3yLSZTcm9XIfQIJC//KeCUmT0a9j/JxEDkIv8vA8+Z2Tkz+yHwIPAL5CP/lKbynubCtEwx\nfTAkvRd4J/DrwahBHvL/FJMBxZOhH28HviTpx4ks/9AG4XFgl6Sdki5jEhrj2MAyrSN8mb8feNrM\nPlI4lEXoDss89IiZvQi8IGka1fFmJqvgs5CfyVTRjZJeF9rSzUy+Q+Ui/5RG8obppe9JujGU+zcL\n1/SOpL1Mpk3fZWb/WziUvPxm9lUz+zEzuy7041NMHF1ejC5/H1/NF3xRv5WJ5843gA8OLU+JfL/I\n5PX4K8CXw9+twI8y+WGgZ4F/Bq4pXPPBUJ5n6MkzoWZZbuKCl1E28gNvAlZDHfwjcHVm8n8I+Brw\nFPB3TDxCkpUf+AST7x0/DA+fO5aRF1gJZf4G8BeEyAgDyb/GZK592of/Kif5Z45/i+BlFFt+D13h\nOI7jAMNPGTmO4ziJ4AbBcRzHAdwgOI7jOAE3CI7jOA7gBsFxHMcJuEFwHMdxADcIjuM4TuD/Afa1\nTIcwf5NnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6ad1f9be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: the visualization is saved to tree.jpg file in the directory where this notebook is,\n",
    "#       it has bigger size\n",
    "if __name__ == '__main__':\n",
    "    emotion = 'anger'\n",
    "    examples, targets = load_clean_data()\n",
    "    binary_targets = to_binary_targets(targets, emotion)\n",
    "    attributes = np.array(['AU_' + str(x+1) for x in range(examples.shape[1])])\n",
    "    tree = decision_tree_learning(examples, attributes, binary_targets)\n",
    "    visualize_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tests one tree, returns depth of classification and classification\n",
    "def classify(tree, features, depth=0):\n",
    "    if tree.classification != None:\n",
    "        return [tree.classification, depth+1]\n",
    "    if features[tree.op-1]==1:\n",
    "        return classify(tree.kids[0], features, depth+1)\n",
    "    else:\n",
    "        return classify(tree.kids[1], features, depth+1)\n",
    "\n",
    "# testTrees(T,x2) from the specs, but named test_trees for style\n",
    "#Tests set of trained trees T on x2\n",
    "def test_trees(T, x2, random=0):\n",
    "    L=[]\n",
    "    for index in range(0,x2.shape[0]):\n",
    "        depths_pos = []\n",
    "        out_pos = []\n",
    "        depths_neg = []\n",
    "        out_neg = []\n",
    "        for t_num in range(0,T.size):\n",
    "            test = classify(T[t_num],x2[index])\n",
    "            \n",
    "            if test[0]==1:\n",
    "                depths_pos.append(test[1])\n",
    "                out_pos.append(t_num+1)\n",
    "            else:\n",
    "                depths_neg.append(test[1])\n",
    "                out_neg.append(t_num+1)\n",
    "        if random:\n",
    "            import random\n",
    "            if len(out_pos)==0:\n",
    "                output=random.randint(1, 6)\n",
    "            else:\n",
    "                output=out_pos[random.randint(0,len(out_pos)-1)]\n",
    "        else:\n",
    "            if len(out_pos)==0:\n",
    "                output = out_neg[depths_neg.index(max(depths_neg))]\n",
    "            else:\n",
    "                output = out_pos[depths_pos.index(min(depths_pos))]\n",
    "        L.append(output)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating confusion matrix\n",
    "\n",
    "def confusion_matrix_10_cross(examples, targets, threshold=0, prune=0,random=0):\n",
    "    k = 10\n",
    "    N = len(targets)\n",
    "    foldN = N // k\n",
    "    confusion_matrix = np.zeros((6,6), dtype=np.int)\n",
    "\n",
    "    #i = ith cross-validation run\n",
    "    for i in range(k):\n",
    "        aux_x = np.vstack((examples[:i*foldN, :], examples[(i+1)*foldN:, :]))\n",
    "        aux_y = np.vstack((targets[:i*foldN, :], targets[(i+1)*foldN:, :]))\n",
    "        if prune:\n",
    "            import random\n",
    "            valid_fold = random.randint(0,k-4)\n",
    "            train_x = np.vstack((aux_x[:valid_fold*foldN, :], aux_x[(valid_fold+3)*foldN:, :]))\n",
    "            train_y = np.vstack((aux_y[:valid_fold*foldN, :], aux_y[(valid_fold+3)*foldN:, :]))\n",
    "            valid_x = aux_x[valid_fold*foldN:(valid_fold+3)*foldN, :]\n",
    "            valid_y = aux_y[valid_fold*foldN:(valid_fold+3)*foldN, :]\n",
    "        else:\n",
    "            train_x=aux_x\n",
    "            train_y=aux_y\n",
    "            \n",
    "        test_x = examples[i*foldN:(i+1)*foldN, :]\n",
    "        test_y = targets[i*foldN:(i+1)*foldN, :]\n",
    "        \n",
    "        attributes = np.arange(1, examples.shape[1]+1)\n",
    "\n",
    "        #Training on train data\n",
    "        L=[]\n",
    "        for i in range(1,7):\n",
    "            tree = decision_tree_learning(train_x, attributes, to_binary_targets(train_y,i), threshold)\n",
    "            if prune:\n",
    "                tree = prune_tree(tree, valid_x, to_binary_targets(valid_y,i))\n",
    "            L.append(tree)\n",
    "        T = np.array(L)\n",
    "\n",
    "        results = test_trees(T, test_x, random)\n",
    "\n",
    "        for i in range(0, test_y.size):\n",
    "            confusion_matrix[test_y[i] - 1, results[i] - 1]+=1\n",
    "\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef test_trees(trees, examples):\\n    res = []\\n    for i,example in enumerate(examples):\\n        max_d = 0\\n        max_e = 0\\n        for j,tree in enumerate(trees):\\n            (c, d) = classify(tree, example)\\n            if c and max_d < d:\\n                max_d = d\\n                max_e = j+1\\n        res.append([(max_e)])\\n    return np.array(res)\\n    \\ndef get_precision(predTargets, trueTargets):\\n    return np.sum(predTargets == trueTargets) / predTargets.size\\n    \\n# k-fold validation\\ndef k_fold_validation(examples, targets, k, prune=False):\\n    N = len(examples)\\n    foldN = N // k\\n    precs = []\\n    for i in range(k):\\n        print('Fold ' + str(i))\\n        training_examples = np.vstack((examples[:i*foldN, :], examples[(i+1)*foldN:, :]))\\n        training_targets = np.vstack((targets[:i*foldN, :], targets[(i+1)*foldN:, :]))\\n        validation_examples = np.array([])\\n        validation_targets = np.array([])\\n        if prune:\\n            T = len(training_examples)\\n            validation_examples = training_examples[:(T//(k-1))]\\n            validation_targets  = training_targets[:(T//(k-1))]\\n            training_examples = training_examples[(T//(k-1)):]\\n            training_targets = training_targets[(T//(k-1)):]\\n        test_examples = examples[i*foldN:(i+1)*foldN, :]\\n        test_targets = targets[i*foldN:(i+1)*foldN, :]\\n        trees = []\\n        for emotion in EMOTIONS:\\n            print('  emotion = ' + emotion)\\n            #attributes = np.array(['AU_' + str(x+1) for x in range(examples.shape[1])])\\n            attributes = np.array(list(range(1, examples.shape[1]+1)))\\n            binary_training_targets = to_binary_targets(training_targets, emotion)\\n            tree = decision_tree_learning(training_examples, attributes, binary_training_targets)\\n            if prune:\\n                tree = prune_tree(tree, validation_examples, validation_targets)\\n            trees.append(tree)\\n        predictions = test_trees(trees, test_examples)\\n        #print(predictions)\\n        precision = get_precision(predictions, test_targets)\\n        print(precision)\\n        precs.append(precision)\\n    print('PRECISION = ' + str(np.mean(np.array(precs))))\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def test_trees(trees, examples):\n",
    "    res = []\n",
    "    for i,example in enumerate(examples):\n",
    "        max_d = 0\n",
    "        max_e = 0\n",
    "        for j,tree in enumerate(trees):\n",
    "            (c, d) = classify(tree, example)\n",
    "            if c and max_d < d:\n",
    "                max_d = d\n",
    "                max_e = j+1\n",
    "        res.append([(max_e)])\n",
    "    return np.array(res)\n",
    "    \n",
    "def get_precision(predTargets, trueTargets):\n",
    "    return np.sum(predTargets == trueTargets) / predTargets.size\n",
    "    \n",
    "# k-fold validation\n",
    "def k_fold_validation(examples, targets, k, prune=False):\n",
    "    N = len(examples)\n",
    "    foldN = N // k\n",
    "    precs = []\n",
    "    for i in range(k):\n",
    "        print('Fold ' + str(i))\n",
    "        training_examples = np.vstack((examples[:i*foldN, :], examples[(i+1)*foldN:, :]))\n",
    "        training_targets = np.vstack((targets[:i*foldN, :], targets[(i+1)*foldN:, :]))\n",
    "        validation_examples = np.array([])\n",
    "        validation_targets = np.array([])\n",
    "        if prune:\n",
    "            T = len(training_examples)\n",
    "            validation_examples = training_examples[:(T//(k-1))]\n",
    "            validation_targets  = training_targets[:(T//(k-1))]\n",
    "            training_examples = training_examples[(T//(k-1)):]\n",
    "            training_targets = training_targets[(T//(k-1)):]\n",
    "        test_examples = examples[i*foldN:(i+1)*foldN, :]\n",
    "        test_targets = targets[i*foldN:(i+1)*foldN, :]\n",
    "        trees = []\n",
    "        for emotion in EMOTIONS:\n",
    "            print('  emotion = ' + emotion)\n",
    "            #attributes = np.array(['AU_' + str(x+1) for x in range(examples.shape[1])])\n",
    "            attributes = np.array(list(range(1, examples.shape[1]+1)))\n",
    "            binary_training_targets = to_binary_targets(training_targets, emotion)\n",
    "            tree = decision_tree_learning(training_examples, attributes, binary_training_targets)\n",
    "            if prune:\n",
    "                tree = prune_tree(tree, validation_examples, validation_targets)\n",
    "            trees.append(tree)\n",
    "        predictions = test_trees(trees, test_examples)\n",
    "        #print(predictions)\n",
    "        precision = get_precision(predictions, test_targets)\n",
    "        print(precision)\n",
    "        precs.append(precision)\n",
    "    print('PRECISION = ' + str(np.mean(np.array(precs))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "#    x, y = load_clean_data()\n",
    "#    k_fold_validation(x, y, 10, prune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 89  19   4   4  13   2]\n [ 18 150   1  10  12   7]\n [  4   6  88   3   3  14]\n [  1  12   3 183  11   5]\n [ 25  16   7   8  72   4]\n [  3   5  15   6   9 168]]\n0.75\n1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90  20   3   3  13   2]\n [ 17 152   1   9  12   7]\n [  5   6  87   2   3  15]\n [  1  13   1 185  10   5]\n [ 25  17   4   8  74   4]\n [  2   5  12   6  12 169]]\n0.757\n2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92  18   3   3  13   2]\n [ 15 154   0   9  13   7]\n [  2   6  89   2   4  15]\n [  1  14   0 186  10   4]\n [ 21  18   4   8  77   4]\n [  2   9   9   6  10 170]]\n0.768\n3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   4   3   4  18   2]\n [ 18 149   2   8  16   5]\n [  2   4  89   3   6  14]\n [  1   9   0 190  11   4]\n [ 20   9   5   8  83   7]\n [  3   3  10   6  11 173]]\n0.784\n4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   4   3   4  17   2]\n [ 17 154   2   8  14   3]\n [  3   4  89   3   5  14]\n [  0   9   0 191  10   5]\n [ 19  10   5   8  82   8]\n [  2   5  11   6   9 173]]\n0.79\n5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   5   5   4  17   0]\n [ 11 157   4   7  16   3]\n [  3   4  93   3   4  11]\n [  0   7   0 202   3   3]\n [ 22  12   5   7  77   9]\n [  8   6  12   6   8 166]]\n0.795\n6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95   6   7   6  17   0]\n [  9 160   4   6  16   3]\n [  4   4  93   3   3  11]\n [  0   7   0 202   3   3]\n [ 25  12   5   7  78   5]\n [ 10   6  13   8   7 162]]\n0.79\n7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 91   7   9   5  19   0]\n [  6 163   7   5  15   2]\n [  2   5  94   3   2  12]\n [ 10   5   3 189   5   3]\n [ 19  12   5  11  79   6]\n [  4   6  13  13   8 162]]\n0.778\n8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98   7   9   7   9   1]\n [ 14 160  11   3   8   2]\n [  3   4  97   2   0  12]\n [ 17   5   5 184   1   3]\n [ 53  12   6  10  34  17]\n [ 10   5  17  10   3 161]]\n0.734\n9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   7  10   5   0   1]\n [ 20 161  13   2   0   2]\n [  3   4  97   2   0  12]\n [ 20   5   5 182   0   3]\n [ 84  12   7   7   0  22]\n [ 15   5  18   6   0 162]]\n0.71\n10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  10  10   5   0   1]\n [ 20 162  13   2   0   1]\n [  3   4  96   3   0  12]\n [ 20   5   5 182   0   3]\n [ 83  13   7   7   0  22]\n [ 15   5  18   6   0 162]]\n0.707\n11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102  12  10   5   0   2]\n [ 21 160  13   2   0   2]\n [  4   5  95   2   0  12]\n [ 20   6   4 182   0   3]\n [ 82  14   8   7   0  21]\n [ 15   3  20   6   0 162]]\n0.701\n12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 84  28  11   6   0   2]\n [ 17 168  11   1   0   1]\n [  5   6  95   2   0  10]\n [ 19  10   4 179   0   3]\n [ 70  26   8   7   0  21]\n [ 13   7  19   6   0 161]]\n0.687\n13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16  80  16  11   0   8]\n [  2 182  12   2   0   0]\n [  2   8  96   2   0  10]\n [  7  22   4 179   0   3]\n [ 20  74   9   9   0  20]\n [  0  21  19   6   0 160]]\n0.633\n14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  96  16  12   0   7]\n [  0 184  12   2   0   0]\n [  0   9  97   2   0  10]\n [  0  32   4 176   0   3]\n [  0  92   9  11   0  20]\n [  0  22  19   7   0 158]]\n0.615\n15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  97  17  10   0   7]\n [  0 184  12   2   0   0]\n [  0   9  98   1   0  10]\n [  0  32   4 176   0   3]\n [  0  92   9  11   0  20]\n [  0  23  20   5   0 158]]\n0.616\n16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  97  17  10   0   7]\n [  0 185  12   1   0   0]\n [  0   9  98   3   0   8]\n [  0  32   4 176   0   3]\n [  0  92   9  11   0  20]\n [  0  24  20   6   0 156]]\n0.615\n17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  97  17  11   0   6]\n [  0 185  12   1   0   0]\n [  0  14  93   3   0   8]\n [  0  39   4 169   0   3]\n [  0  92   9  11   0  20]\n [  0  24  20   7   0 155]]\n0.602\n18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  99  15  11   0   6]\n [  0 187  10   1   0   0]\n [  0  15  80   7   0  16]\n [  0  43   3 166   0   3]\n [  0  92   9  11   0  20]\n [  0  25  17   7   0 157]]\n0.59\n19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 101  13  11   0   6]\n [  0 188   9   1   0   0]\n [  0  20  70   7   0  21]\n [  0  48   3 162   0   2]\n [  0  93   8  12   0  19]\n [  0  28  17   9   0 152]]\n0.572\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    x, y = load_clean_data()\n",
    "    for i in range(20):\n",
    "        print(i)\n",
    "        cm = confusion_matrix_10_cross(x,y,prune=0,threshold=0.01*i)\n",
    "        print(cm)\n",
    "        print((cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4]+cm[5,5])/np.sum(cm))\n",
    "        \n",
    "    '''\n",
    "    cm = confusion_matrix_10_cross(x,y,prune=1,threshold=0.01)\n",
    "    print(cm)\n",
    "    print((cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4]+cm[5,5])/np.sum(cm))\n",
    "\n",
    "    cm = confusion_matrix_10_cross(x,y,prune=0,threshold=0.01)\n",
    "    print(cm)\n",
    "    print((cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4]+cm[5,5])/np.sum(cm))\n",
    "    \n",
    "    cm = confusion_matrix_10_cross(x,y,prune=1,random=1,threshold=0.01)\n",
    "    print(cm)\n",
    "    print((cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4]+cm[5,5])/np.sum(cm))\n",
    "      \n",
    "    cm = confusion_matrix_10_cross(x,y,prune=0,random=1,threshold=0.01)\n",
    "    print(cm)\n",
    "    print((cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4]+cm[5,5])/np.sum(cm))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}